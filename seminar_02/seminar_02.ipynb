{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 2: Работа с данными и создание нейронных сетей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск ошибок в архитектурах нейронных сетей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 1\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.drop1 = nn.Dropout2d(0.5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.fc = nn.Linear(128 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.drop1(self.bn1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model1 = CNN1()\n",
    "# test_input = torch.randn(1, 3, 64, 64)\n",
    "# output = model1(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель 2\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model2 = CNN2()\n",
    "test_input = torch.randn(1, 3, 64, 64)\n",
    "output = model2(test_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.branch1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.branch2 = nn.Conv2d(3, 128, 5, padding=2)\n",
    "        self.fc = nn.Linear(192 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.branch1(x))\n",
    "        b2 = F.relu(self.branch2(x))\n",
    "        out = torch.cat([b1, b2], dim=0)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model3 = CNN3()\n",
    "test_input = torch.randn(1, 3, 64, 64)\n",
    "output = model3(test_input)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание собственного DataLoader\n",
    "\n",
    "\n",
    "### Что такое Dataset?\n",
    "- **Dataset** - это класс, который индексирует и возвращает один образец данных\n",
    "- **DataLoader** - это итератор, который группирует данные в батчи и предоставляет многопроцессную загрузку\n",
    "\n",
    "### Основные методы Dataset:\n",
    "- `__init__()` - инициализация, загрузка метаданных\n",
    "- `__len__()` - возвращает размер датасета\n",
    "- `__getitem__(idx)` - возвращает элемент по индексу\n",
    "\n",
    "** Создадим собственный DataLoader для Tiny ImageNet:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: путь до папки tiny-imagenet-200\n",
    "        split: 'train', 'val' или 'test'\n",
    "        transform: трансформации изображений\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
    "            self.class_names = [line.strip() for line in f]\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "\n",
    "        self.samples = []\n",
    "        if split == 'train':\n",
    "            train_dir = os.path.join(root_dir, 'train')\n",
    "            for cls in os.listdir(train_dir):\n",
    "                img_dir = os.path.join(train_dir, cls, 'images')\n",
    "                if not os.path.exists(img_dir):\n",
    "                    continue\n",
    "                for img_name in os.listdir(img_dir):\n",
    "                    img_path = os.path.join(img_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        elif split == 'val':\n",
    "            val_dir = os.path.join(root_dir, 'val', 'images')\n",
    "            anno_path = os.path.join(root_dir, 'val', 'val_annotations.txt')\n",
    "\n",
    "            label_map = {}\n",
    "            with open(anno_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    img_name, cls, *_ = line.strip().split('\\t')\n",
    "                    label_map[img_name] = cls\n",
    "\n",
    "            for img_name in os.listdir(val_dir):\n",
    "                cls = label_map.get(img_name)\n",
    "                if cls:\n",
    "                    img_path = os.path.join(val_dir, img_name)\n",
    "                    label = self.class_to_idx[cls]\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        else:\n",
    "            test_dir = os.path.join(root_dir, 'test', 'images')\n",
    "            for img_name in os.listdir(test_dir):\n",
    "                img_path = os.path.join(test_dir, img_name)\n",
    "                self.samples.append((img_path, -1))  # тест без меток\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 72)),                    \n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),                     \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "root = \"data/tiny-imagenet-200\"\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "val_dataset = TinyImageNetDataset(root, split='val', transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "print(f\"Классов: {len(train_dataset.class_names)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    \"\"\"Вернём изображение из нормализованного диапазона в [0,1]\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "    img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "images_vis = images.permute(0, 2, 3, 1)\n",
    "\n",
    "images_vis = torch.stack([denormalize(img) for img in images])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(images_vis[i])\n",
    "    plt.title(f\"Class: {labels[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Примеры изображений из Tiny ImageNet (с аугментациями)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Размер батча: {images.shape}\")\n",
    "print(f\"Диапазон значений: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "print(f\"Метки классов: {labels.tolist()}\")\n",
    "print(f\"Всего классов в датасете: {len(train_dataset.class_names)}\")\n",
    "print(f\"Примеры названий классов: {train_dataset.class_names[:5]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратификация данных\n",
    "\n",
    "### Что такое стратификация?\n",
    "**Стратификация** - это метод разделения данных, при котором сохраняется пропорциональное представление классов в каждой части.\n",
    "\n",
    "###  Зачем нужна стратификация?\n",
    "- Обеспечивает равномерное распределение классов между train/val/test\n",
    "- Предотвращает переобучение на доминирующих классах\n",
    "- Дает более надежную оценку качества модели\n",
    "\n",
    "###  Типы стратификации:\n",
    "1. **Случайная стратификация** - простое случайное разделение\n",
    "2. **K-Fold стратификация** - разделение на k частей\n",
    "3. **Стратификация по эмбедингам** - разделение на основе семантических признаков\n",
    "\n",
    "** Рассмотрим различные подходы:**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод 1: Простая случайная стратификация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Метод 1: Простая случайная стратификация\")\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root, split='train', transform=train_transform)\n",
    "all_samples = train_dataset.samples\n",
    "\n",
    "print(f\" Всего образцов: {len(all_samples)}\")\n",
    "\n",
    "random.seed(42)\n",
    "all_samples_copy = all_samples.copy()\n",
    "random.shuffle(all_samples_copy)\n",
    "\n",
    "val_fraction = 0.2\n",
    "split_idx = int(len(all_samples_copy) * (1 - val_fraction))\n",
    "train_split_random = all_samples_copy[:split_idx]\n",
    "val_split_random = all_samples_copy[split_idx:]\n",
    "\n",
    "print(f\" Случайное разделение:\")\n",
    "print(f\"   Train: {len(train_split_random)} образцов\")\n",
    "print(f\"   Val: {len(val_split_random)} образцов\")\n",
    "\n",
    "def analyze_class_distribution(samples, name):\n",
    "    labels = [label for _, label in samples]\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\" {name} - распределение классов:\")\n",
    "    print(f\"   Минимум: {min(class_counts.values())}\")\n",
    "    print(f\"   Максимум: {max(class_counts.values())}\")\n",
    "    print(f\"   Среднее: {np.mean(list(class_counts.values())):.1f}\")\n",
    "    print(f\"   Стандартное отклонение: {np.std(list(class_counts.values())):.1f}\")\n",
    "\n",
    "analyze_class_distribution(train_split_random, \"Случайное train\")\n",
    "analyze_class_distribution(val_split_random, \"Случайное val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод 2: Cтратификация с помощью sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = [x for x, y in all_samples]  # пути к изображениям\n",
    "y = [y for x, y in all_samples]  # метки классов\n",
    "\n",
    "print(f\" Подготовлено {len(X)} образцов с {len(set(y))} классами\")\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=val_fraction, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X, y))\n",
    "\n",
    "# Создаем стратифицированные разделения\n",
    "train_split_stratified = [all_samples[i] for i in train_idx]\n",
    "val_split_stratified = [all_samples[i] for i in val_idx]\n",
    "\n",
    "print(f\" Стратифицированное разделение:\")\n",
    "print(f\"   Train: {len(train_split_stratified)} образцов\")\n",
    "print(f\"   Val: {len(val_split_stratified)} образцов\")\n",
    "\n",
    "# Анализируем распределение классов\n",
    "analyze_class_distribution(train_split_stratified, \"Стратифицированное train\")\n",
    "analyze_class_distribution(val_split_stratified, \"Стратифицированное val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метод 3: K-Fold стратификация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold стратификация\n",
    "\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\" Разделение на {k} фолдов:\")\n",
    "fold_splits = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    train_split = [all_samples[i] for i in train_idx]\n",
    "    val_split = [all_samples[i] for i in val_idx]\n",
    "    fold_splits.append((train_split, val_split))\n",
    "    print(f\"   Fold {fold}: train={len(train_split)}, val={len(val_split)}\")\n",
    "\n",
    "print(f\" Анализ первого фолда:\")\n",
    "analyze_class_distribution(fold_splits[0][0], \"Fold 0 train\")\n",
    "analyze_class_distribution(fold_splits[0][1], \"Fold 0 val\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стратификация через эмбединги\n",
    "\n",
    "## Что такое стратификация через эмбединги?\n",
    "Вместо разделения по классам, мы можем разделить данные по **семантическим признакам** (эмбедингам), извлеченным из изображений.\n",
    "\n",
    "### Преимущества:\n",
    "- Учитывает визуальное сходство изображений\n",
    "- Может найти скрытые паттерны в данных\n",
    "- Полезно когда классы неоднородны внутри себя\n",
    "\n",
    "### Алгоритм:\n",
    "1. Извлекаем эмбединги с помощью предобученной модели\n",
    "2. Кластеризуем эмбединги (K-means)\n",
    "3. Стратифицируем по кластерам\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Создание подвыборки для демонстрации\n",
    "\n",
    "Для демонстрации возьмем только несколько классов, чтобы ускорить процесс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_classes = [0, 5, 10, 15, 20]  # 5 классов\n",
    "subset_samples = [s for s in train_dataset.samples if s[1] in selected_classes]\n",
    "\n",
    "print(f\"Используем {len(subset_samples)} изображений из {len(selected_classes)} классов\")\n",
    "print(f\"Выбранные классы: {selected_classes}\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_subset_dataset = CustomDataset(subset_samples, transform=train_transform)\n",
    "subset_loader = DataLoader(train_subset_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Создан датасет с {len(train_subset_dataset)} образцами\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Извлечение эмбедингов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧠 Извлекаем эмбединги...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🖥️ Используем устройство: {device}\")\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# Создаем feature extractor (убираем последний слой)\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "def extract_embeddings(images):\n",
    "    \"\"\"\n",
    "    Извлекаем эмбединги из изображений\n",
    "    images: батч [B, 3, H, W]\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = feature_extractor(images)  # [B, 2048, 1, 1]\n",
    "        x = x.view(x.size(0), -1)      # [B, 2048]\n",
    "    return x\n",
    "\n",
    "# Извлекаем эмбединги для всех изображений\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Извлекаем эмбединги для всех изображений...\")\n",
    "for images, labels in tqdm(subset_loader, desc=\"Извлечение эмбедингов\"):\n",
    "    images = images.to(device)\n",
    "    emb = extract_embeddings(images)  # [B, 2048]\n",
    "    all_embeddings.append(emb.cpu())\n",
    "    all_labels.append(labels)\n",
    "\n",
    "all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "print(f\"Извлечено эмбедингов: {all_embeddings.shape}\")\n",
    "print(f\"Размерность эмбединга: {all_embeddings.shape[1]}\")\n",
    "print(f\"Количество меток: {len(all_labels)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: K-means кластеризация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "\n",
    "pseudo_labels = kmeans.fit_predict(all_embeddings)\n",
    "\n",
    "print(f\"Создано {n_clusters} кластеров\")\n",
    "print(f\"Распределение по кластерам: {Counter(pseudo_labels)}\")\n",
    "\n",
    "# Анализируем соответствие кластеров и исходных классов\n",
    "cluster_class_mapping = {}\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_indices = np.where(pseudo_labels == cluster_id)[0]\n",
    "    cluster_classes = all_labels[cluster_indices]\n",
    "    most_common_class = Counter(cluster_classes).most_common(1)[0]\n",
    "    cluster_class_mapping[cluster_id] = most_common_class\n",
    "    print(f\"📊 Кластер {cluster_id}: {len(cluster_indices)} образцов, \"\n",
    "          f\"доминирующий класс {most_common_class[0]} ({most_common_class[1]} образцов)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: Визуализация кластеров с помощью PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Применяем PCA для снижения размерности до 2D\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "emb_2d = pca.fit_transform(all_embeddings)\n",
    "\n",
    "print(f\"PCA объясняет {pca.explained_variance_ratio_.sum():.3f} дисперсии\")\n",
    "print(f\"Компонента 1: {pca.explained_variance_ratio_[0]:.3f}\")\n",
    "print(f\"Компонента 2: {pca.explained_variance_ratio_[1]:.3f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Визуализация по кластерам\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "for cluster in range(n_clusters):\n",
    "    indices = np.where(pseudo_labels == cluster)[0]\n",
    "    ax1.scatter(emb_2d[indices, 0], emb_2d[indices, 1], \n",
    "               c=[colors[cluster]], label=f'Cluster {cluster}', s=20, alpha=0.7)\n",
    "\n",
    "ax1.set_title(\"Кластеризация K-means в 2D пространстве\")\n",
    "ax1.set_xlabel(\"PC1\")\n",
    "ax1.set_ylabel(\"PC2\")\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Визуализация по исходным классам\n",
    "class_colors = plt.cm.Set1(np.linspace(0, 1, len(selected_classes)))\n",
    "for i, class_id in enumerate(selected_classes):\n",
    "    indices = np.where(all_labels == class_id)[0]\n",
    "    ax2.scatter(emb_2d[indices, 0], emb_2d[indices, 1], \n",
    "               c=[class_colors[i]], label=f'Class {class_id}', s=20, alpha=0.7)\n",
    "\n",
    "ax2.set_title(\"Исходные классы в 2D пространстве\")\n",
    "ax2.set_xlabel(\"PC1\")\n",
    "ax2.set_ylabel(\"PC2\")\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Анализ качества кластеризации:\")\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "ari_score = adjusted_rand_score(all_labels, pseudo_labels)\n",
    "nmi_score = normalized_mutual_info_score(all_labels, pseudo_labels)\n",
    "\n",
    "print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
    "print(f\"Normalized Mutual Information: {nmi_score:.3f}\")\n",
    "print(\"Чем выше значения, тем лучше кластеризация соответствует исходным классам\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Стратификация по кластерам\n",
    "\n",
    "Теперь разделим данные на train/val используя кластеры вместо исходных классов:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Стратифицируем данные по кластерам...\")\n",
    "\n",
    "sss_embedding = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx_embedding, val_idx_embedding = next(sss_embedding.split(subset_samples, pseudo_labels))\n",
    "\n",
    "train_samples_embedding = [subset_samples[i] for i in train_idx_embedding]\n",
    "val_samples_embedding = [subset_samples[i] for i in val_idx_embedding]\n",
    "\n",
    "print(f\" Стратификация по эмбедингам:\")\n",
    "print(f\"   Train: {len(train_samples_embedding)} образцов\")\n",
    "print(f\"   Val: {len(val_samples_embedding)} образцов\")\n",
    "\n",
    "def analyze_embedding_split(samples, name):\n",
    "    labels = [label for _, label in samples]\n",
    "    class_counts = Counter(labels)\n",
    "    print(f\"📊 {name} - распределение исходных классов:\")\n",
    "    for class_id in selected_classes:\n",
    "        count = class_counts.get(class_id, 0)\n",
    "        percentage = count / len(labels) * 100\n",
    "        print(f\"   Класс {class_id}: {count} образцов ({percentage:.1f}%)\")\n",
    "\n",
    "analyze_embedding_split(train_samples_embedding, \"Train (по эмбедингам)\")\n",
    "analyze_embedding_split(val_samples_embedding, \"Val (по эмбедингам)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Часть 5: DataLoader с OpenCV и Albumentations\n",
    "\n",
    "### Зачем использовать OpenCV?\n",
    "- **Быстрее** чем PIL для некоторых операций\n",
    "- **Больше возможностей** для аугментаций\n",
    "- **Лучшая интеграция** с библиотекой Albumentations\n",
    "- **Поддержка** различных форматов изображений\n",
    "\n",
    "####  Что такое Albumentations?\n",
    "- Современная библиотека для аугментаций\n",
    "- Оптимизирована для компьютерного зрения\n",
    "- Поддерживает как PIL, так и OpenCV\n",
    "- Простой и гибкий API\n",
    "\n",
    "** Создадим DataLoader с OpenCV и Albumentations:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetAlbumentationsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет Tiny ImageNet с OpenCV + Albumentations\n",
    "    \n",
    "    Преимущества:\n",
    "    - Быстрая загрузка через OpenCV\n",
    "    - Мощные аугментации через Albumentations\n",
    "    - Поддержка различных форматов\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split='train', augmentation=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "        # Загружаем названия классов\n",
    "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
    "            self.class_names = [line.strip() for line in f.readlines()]\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
    "        \n",
    "        print(f\"📊 Найдено {len(self.class_names)} классов\")\n",
    "\n",
    "        # Собираем данные\n",
    "        self.samples = self._make_dataset()\n",
    "        print(f\"📁 Загружено {len(self.samples)} образцов для {self.split}\")\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        \"\"\"Создаем список образцов данных\"\"\"\n",
    "        data = []\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = self._load_train_data()\n",
    "        elif self.split == 'val':\n",
    "            data = self._load_val_data()\n",
    "        elif self.split == 'test':\n",
    "            data = self._load_test_data()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {self.split}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _load_train_data(self):\n",
    "        \"\"\"Загружаем тренировочные данные\"\"\"\n",
    "        data = []\n",
    "        train_dir = os.path.join(self.root_dir, 'train')\n",
    "        for cls_name in os.listdir(train_dir):\n",
    "            img_dir = os.path.join(train_dir, cls_name, 'images')\n",
    "            if not os.path.isdir(img_dir):\n",
    "                continue\n",
    "            for img_name in os.listdir(img_dir):\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                label = self.class_to_idx[cls_name]\n",
    "                data.append((img_path, label))\n",
    "        return data\n",
    "\n",
    "    def _load_val_data(self):\n",
    "        \"\"\"Загружаем валидационные данные\"\"\"\n",
    "        data = []\n",
    "        val_dir = os.path.join(self.root_dir, 'val')\n",
    "        img_dir = os.path.join(val_dir, 'images')\n",
    "        anno_file = os.path.join(val_dir, 'val_annotations.txt')\n",
    "\n",
    "        label_map = {}\n",
    "        with open(anno_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                img_name, cls_name, *_ = line.strip().split('\\t')\n",
    "                label_map[img_name] = self.class_to_idx[cls_name]\n",
    "\n",
    "        for img_name in os.listdir(img_dir):\n",
    "            if img_name in label_map:\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                label = label_map[img_name]\n",
    "                data.append((img_path, label))\n",
    "        return data\n",
    "\n",
    "    def _load_test_data(self):\n",
    "        \"\"\"Загружаем тестовые данные\"\"\"\n",
    "        data = []\n",
    "        test_dir = os.path.join(self.root_dir, 'test', 'images')\n",
    "        for img_name in os.listdir(test_dir):\n",
    "            img_path = os.path.join(test_dir, img_name)\n",
    "            data.append((img_path, -1))  # нет меток\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Возвращаем образец по индексу\"\"\"\n",
    "        img_path, label = self.samples[idx]\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
    "\n",
    "\n",
    "        # Применяем аугментации\n",
    "        if self.augmentation:\n",
    "            augmented = self.augmentation(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img, label\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание аугментаций с помощью Albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем мощные аугментации с помощью Albumentations\n",
    "\n",
    "train_aug = A.Compose([\n",
    "    # Изменение размера\n",
    "    A.Resize(72, 72),\n",
    "    A.RandomResizedCrop(64, 64, scale=(0.8, 1.0)),\n",
    "    \n",
    "    # Геометрические трансформации\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    \n",
    "    # Цветовые аугментации\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "    \n",
    "    # Шум и размытие\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    \n",
    "    # Нормализация и преобразование в тензор\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Валидационные аугментации (только базовые)\n",
    "val_aug = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset_cv = TinyImageNetAlbumentationsDataset(\n",
    "    root_dir=\"data/tiny-imagenet-200\",\n",
    "    split=\"train\",\n",
    "    augmentation=train_aug\n",
    ")\n",
    "\n",
    "val_dataset_cv = TinyImageNetAlbumentationsDataset(\n",
    "    root_dir=\"data/tiny-imagenet-200\",\n",
    "    split=\"val\",\n",
    "    augmentation=val_aug\n",
    ")\n",
    "\n",
    "train_loader_cv = DataLoader(train_dataset_cv, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader_cv = DataLoader(val_dataset_cv, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset_cv)}\")\n",
    "print(f\"Val size: {len(val_dataset_cv)}\")\n",
    "\n",
    "print(\"Тестируем OpenCV DataLoader...\")\n",
    "images_cv, labels_cv = next(iter(train_loader_cv))\n",
    "\n",
    "print(f\"Размер батча: {images_cv.shape}\")\n",
    "print(f\"Тип данных: {images_cv.dtype}\")\n",
    "print(f\"Диапазон значений: [{images_cv.min():.3f}, {images_cv.max():.3f}]\")\n",
    "\n",
    "# Визуализируем результаты\n",
    "def denormalize_cv(img_tensor):\n",
    "    \"\"\"Денормализация для OpenCV изображений\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n",
    "    img = img_tensor.permute(1, 2, 0) * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    img_vis = denormalize_cv(images_cv[i])\n",
    "    plt.imshow(img_vis)\n",
    "    plt.title(f\"Class: {labels_cv[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"OpenCV + Albumentations DataLoader\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Создание кастомной ResNet модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполните пропуски в BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Базовый блок ResNet с residual connection\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): количество входных каналов\n",
    "        out_channels (int): количество выходных каналов\n",
    "        stride (int): шаг свертки (по умолчанию 1)\n",
    "        downsample (nn.Module): слой для изменения размерности (если нужно)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "basic_block = BasicBlock(64, 64)\n",
    "test_input = torch.randn(2, 64, 32, 32)\n",
    "\n",
    "output = basic_block(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck блок ResNet (1x1 -> 3x3 -> 1x1)\n",
    "    Более эффективен для глубоких сетей\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): количество входных каналов\n",
    "        out_channels (int): количество выходных каналов\n",
    "        stride (int): шаг свертки\n",
    "        downsample (nn.Module): слой для изменения размерности\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "bottleneck_block = BottleneckBlock(64, 256)\n",
    "test_input = torch.randn(2, 64, 32, 32)\n",
    "\n",
    "output = bottleneck_block(test_input)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleResNet18(num_classes=200)\n",
    "test_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "output = model(test_input)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\" Всего параметров: {total_params:,}\")\n",
    "print(f\" Обучаемых параметров: {trainable_params:,}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "def train_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Функция для одного эпоха обучения\n",
    "    \n",
    "    Args:\n",
    "        model: модель для обучения\n",
    "        train_loader: DataLoader с тренировочными данными\n",
    "        optimizer: оптимизатор\n",
    "        criterion: функция потерь\n",
    "        device: устройство (cpu/cuda)\n",
    "    \n",
    "    Returns:\n",
    "        train_loss: средняя потеря за эпох\n",
    "        train_acc: средняя точность за эпох\n",
    "    \"\"\"\n",
    "    model.train()  # Переводим модель в режим обучения\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "\n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return 0.0, 0.0  # TODO: Замените на правильные значения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Задание 2: Функция валидации (Заготовка)\n",
    "\n",
    "Напишите функцию для валидации модели:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Функция для валидации модели\n",
    "    \n",
    "    Args:\n",
    "        model: модель для валидации\n",
    "        val_loader: DataLoader с валидационными данными\n",
    "        criterion: функция потерь\n",
    "        device: устройство (cpu/cuda)\n",
    "    \n",
    "    Returns:\n",
    "        val_loss: средняя потеря на валидации\n",
    "        val_acc: средняя точность на валидации\n",
    "    \"\"\"\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "\n",
    "            pass\n",
    "    \n",
    "    return 0.0, 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Основная функция для обучения модели\n",
    "    \n",
    "    Args:\n",
    "        model: модель для обучения\n",
    "        train_loader: DataLoader с тренировочными данными\n",
    "        val_loader: DataLoader с валидационными данными\n",
    "        optimizer: оптимизатор\n",
    "        criterion: функция потерь\n",
    "        device: устройство (cpu/cuda)\n",
    "        num_epochs: количество эпох\n",
    "    \n",
    "    Returns:\n",
    "        history: словарь с историей обучения\n",
    "    \"\"\"\n",
    "    print(f\"Обучение на {num_epochs} эпох...\")\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\" Эпоха {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\" Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\" Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\" Сохранена лучшая модель с точностью {val_acc:.2f}%\")\n",
    "        \n",
    "    \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history['train_acc'], label='Train Accuracy', color='blue')\n",
    "    ax2.plot(history['val_acc'], label='Validation Accuracy', color='red')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для быстрого теста можно использовать только несколько классов\n",
    "\n",
    "selected_classes = [0, 5, 10]\n",
    "\n",
    "subset_train_samples = [s for s in train_dataset.samples if s[1] in selected_classes]\n",
    "subset_val_samples = [s for s in val_dataset.samples if s[1] in selected_classes]\n",
    "\n",
    "print(f\"Используем {len(subset_train_samples)} train и {len(subset_val_samples)} val изображений \"\n",
    "      f\"из {len(selected_classes)} классов\")\n",
    "\n",
    "# Перенумеровка классов\n",
    "class_to_new_idx = {cls: i for i, cls in enumerate(selected_classes)}\n",
    "\n",
    "def remap_samples(samples):\n",
    "    return [(path, class_to_new_idx[label]) for path, label in samples]\n",
    "\n",
    "subset_train_samples = remap_samples(subset_train_samples)\n",
    "subset_val_samples = remap_samples(subset_val_samples)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "train_subset_dataset = CustomDataset(subset_train_samples, transform=train_transform)\n",
    "val_subset_dataset = CustomDataset(subset_val_samples, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_subset_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SimpleResNet18(BasicBlock, [2, 2, 2, 2], num_classes=200)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    num_epochs=5\n",
    ")\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
