# Домашнее задание (по мотивам ДЗ-2): Классификация 128x128 + U-Net c бэкбоном

## Цели
- Собрать и обучить собственную модель классификации изображений (128×128) на датасете из семинара 2.
- Реализовать простую модель U-Net, формализовав архитектурные ограничения (параметры/глубина/каналы), и обучить её на датасете «луна» из семинара 3.
- Использовать обученный классификатор в качестве энкодера (бэкбона) в вашей U‑Net и переобучить/дообучить сегментационную модель.
- Представить метрики и краткие выводы.

## Датасеты
- Классификация: Tiny ImageNet-200 из семинара 2.
  - Путь (в этом репозитории): `tiny-imagenet-200/` или `sem2/data/tiny-imagenet-200/`
  - Разрешение: приведите вход к 128×128 (ресайз/кроп по вашему выбору, главное — корректно описать в отчёте).
- Сегментация: MOON_SEGMENTATION_BINARY из семинара 3.
  - Путь: `designing_neural_network_architectures_2025_01/seminar_03/data/MOON_SEGMENTATION_BINARY/` (или аналогичный внутри семинара 3)
  - Структура: `images/render/*.png` — входы, `images/ground/*.png` — бинарные маски.

## Часть 1. Классификатор 128×128
- Требования к модели:
  - Своя архитектура (разрешается вдохновляться CNN-идеями: Conv-BN-ReLU, блоки с даунсемплингом, GAP и т.д.).
  - Ограничение на параметризованность: не более ~5M параметров.
  - Вход: 128×128×3.
- Обучение:
  - Трен/вал сплит: используйте стандартный `train/val` из Tiny ImageNet-200.
  - Аугментации: разумные (кроп, флипы, color jitter), кратко опишите в отчёте.
  - Оптимизатор/план обучения: на ваше усмотрение (например, Adam/SGD + Cosine/StepLR).
- Что сдаём по части 1:
  - Краткое описание архитектуры (количество блоков, каналы, где даунсемплинг, сколько параметров, размер выходного слоя = числу классов).
  - График/лог обучения (loss/accuracy по эпохам) и итоговые метрики на валидации: Top-1 accuracy (обязательно), дополнительно — macro F1 (по желанию).
  - Чекпоинт модели (по возможности) или веса/ссылка.

## Часть 2. Базовая U-Net на «луне»
- Требования к архитектуре U-Net (зафиксируйте и опишите в отчёте):
  - Глубина: 4 уровня down/4 up (энкодер-декодер с skip-связями).
  - Базовые каналы на первом уровне: 32 или 64 (рекомендуется 32 для компактности).
  - Даунсемплинг: стрид 2 или MaxPool.
  - Итоговый слой: 1 канал с сигмоидой (бинарная сегментация).
  - Ограничение на количество параметров: до ~2.5M (рекомендуется укладываться, но допускается ±10%).
- Обучение:
  - Лосс: BCEWithLogitsLoss или Dice Loss, допустимо комбинировать (например, 0.5*BCE + 0.5*Dice).
  - Метрики для мониторинга: IoU (Jaccard), Dice, Pixel Accuracy.
  - Аугментации: горизонтальные/вертикальные флипы, лёгкие геометрические и цветовые — по желанию.
- Что сдаём по части 2:
  - Чёткие архитектурные параметры (глубина, каналы, где даунсемплинг, сколько параметров).
  - Логи обучения и итоговые метрики на валидации: IoU, Dice, Pixel Acc.
  - 3–5 визуализаций: вход, предсказанная маска, GT маска.

## Часть 3. U-Net с бэкбоном из классификатора
- Идея: использовать энкодер из вашей модели классификации как бэкбон U‑Net.
  - Вариант A (заморозка): заморозить веса энкодера, обучать только декодер + 1×1 адаптацию каналов.
  - Вариант B (тонкая настройка): частично/полностью разморозить энкодер на поздних этапах.
  - Если у классификатора есть GAP/FC-голова — удалите её; возьмите сверточные блоки до глобального усреднения как энкодерные стадии.
- Ограничения и замечания:
  - Сохраните совместимость по пространственным масштабам (U‑Net обычно требует 4–5 даунсемплингов с кратностью 2).
  - Если количество стадий не совпадает, добавьте адаптационные 1×1 свёртки и интерполяции/пулинг, но опишите это.
- Обучение:
  - Тот же датасет «луна», те же метрики.
  - Сравните результаты с базовой U‑Net из части 2 (таблица метрик).
- Что сдаём по части 3:
  - Схему, как встроили энкодер из классификатора (какие карты признаков идут в skip-связи, какие масштабы).
  - Метрики и сравнение с базовой U‑Net (желательно таблица).

## Отчёт и что предоставить
- Короткий отчёт (Markdown или ноутбук) с:
  - Описанием архитектур (часть 1/2/3), числом параметров, ключевыми решениями.
  - Графиками обучения и таблицами метрик:
    - Классификация: Top‑1 accuracy (обязательно), опционально F1 macro.
    - Сегментация: IoU, Dice, Pixel Accuracy.
  - Визуализации для сегментации (3–5 примеров).
  - Сравнение базовой U‑Net и U‑Net с бэкбоном.
- Код:
  - Скрипты/ноутбуки для обучения/валидации, явные пути к данным.
  - Чекпоинты или ссылки на веса (если размер мешает — укажите ссылку).

## Мини‑рекомендации по реализации
- Нормализация входа и корректный препроцесс (особенно важно для переноса энкодера в U‑Net).
- Следите за балансом класса в лунных масках; можно использовать взвешенный BCE или Dice.
- ЛР‑план: часто помогает CosineAnnealing или ReduceLROnPlateau.
- Ранняя остановка по IoU/Dice на валидации приветствуется.

## Критерии оценки (ориентир)
- Корректность и чистота реализации: 30%
- Классификатор (качество и описание): 20%
- Базовая U‑Net (качество и описание): 25%
- U‑Net с бэкбоном (интеграция и сравнение): 25%

## Как запустить (примерные указания)
- Классификация: подготовьте даталоадеры для `tiny-imagenet-200`, ресайз до 128×128, обучите `Classifier128` и сохраните чекпоинт.
- Базовая U‑Net: подготовьте загрузку пар (render, ground), обучите `UNetBase`.
- U‑Net + бэкбон: инициализируйте `UNetBackbone` энкодером из `Classifier128` (без финальной головы), обучите и сравните.

Опишите ваши точные команды/конфиги в отчёте, чтобы эксперимент воспроизводился.

***
Если в структуре путей вашего окружения папки отличаются от указанных — добавьте явные пути к данным в отчёт.

